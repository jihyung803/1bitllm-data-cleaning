{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bffb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m203.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m159.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.5 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install numpy pandas\n",
    "!pip install sentencepiece\n",
    "!pip install json\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3a40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tokenization_bitnet import BitnetTokenizer\n",
    "from modeling_bitnet import BitnetForCausalLM\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513d6742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c669ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0c7aaa6d1c49dcb84a29769beb3f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='1bitLLM/bitnet_b1_58-3B'\n",
    "model = BitnetForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    low_cpu_mem_usage=True,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.float16,\n",
    ").half()\n",
    "\n",
    "tokenizer = BitnetTokenizer.from_pretrained(model_name, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065816db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Bits and Bytes 설정\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,  # 4-bit Quantization\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 (NF4)\n",
    "#     bnb_4bit_compute_dtype=torch.float16  # Use FP16 for computations\n",
    "# )\n",
    "\n",
    "# # 모델 로드 (초기화된 상태에서 로드)\n",
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\"\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53410631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data:\n",
      "   i_w_blo_weg  o_w_blo_power  o_w_blo_voltage  i_w_bhl_weg  o_w_bhl_power  \\\n",
      "0       -107.0            0.0              0.0          0.0            0.0   \n",
      "1       -107.0            0.0              0.0          0.0            NaN   \n",
      "2       -107.0            0.0              0.0          0.0            0.0   \n",
      "3       -107.0            0.0              0.0          0.0            0.0   \n",
      "4       -107.0            0.0              0.0          0.0            0.0   \n",
      "\n",
      "   o_w_bhl_voltage  i_w_bhr_weg  o_w_bhr_power  o_w_bhr_voltage  i_w_bru_weg  \\\n",
      "0              0.0      -1268.0            0.0              0.0        -26.0   \n",
      "1              0.0      -1268.0            0.0              0.0        -26.0   \n",
      "2              0.0      -1268.0            0.0              0.0        -26.0   \n",
      "3              0.0      -1268.0            0.0              0.0         29.0   \n",
      "4              0.0      -1268.0            0.0              0.0         29.0   \n",
      "\n",
      "   o_w_bru_power  o_w_bru_voltage  i_w_hr_weg  o_w_hr_power  o_w_hr_voltage  \\\n",
      "0           84.0             11.0         0.0        7168.0            26.0   \n",
      "1           84.0             11.0         0.0        7168.0            26.0   \n",
      "2           84.0             11.0         0.0        7168.0            26.0   \n",
      "3        21725.0             54.0         0.0        6726.0            26.0   \n",
      "4        21725.0             54.0         0.0        6726.0            26.0   \n",
      "\n",
      "   i_w_hl_weg  o_w_hl_power  o_w_hl_voltage  labels  \n",
      "0         0.0        7720.0            24.0       0  \n",
      "1         0.0        7720.0            24.0       0  \n",
      "2         0.0        7720.0            24.0       0  \n",
      "3         0.0       10756.0            26.0       0  \n",
      "4         0.0       10756.0            26.0       0  \n"
     ]
    }
   ],
   "source": [
    "# 파일 경로\n",
    "file_path = \"./dirty.csv\"\n",
    "\n",
    "# CSV 데이터 로드\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Loaded Data:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0cb87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_with_llm_in_batches(rows, batch_size=5):\n",
    "    \"\"\"\n",
    "    Cleans rows of data using an LLM with batch processing to handle token length limits.\n",
    "    \"\"\"\n",
    "    # 샘플 데이터 및 간소화된 프롬프트\n",
    "    examples = [\n",
    "        {\n",
    "            \"i_w_blo_weg\": -9999.0,\n",
    "            \"o_w_blo_power\": \"nan\",\n",
    "            \"o_w_blo_voltage\": -10.0,\n",
    "            \"i_w_bhl_weg\": 0.0,\n",
    "            \"o_w_bhl_power\": 0.0,\n",
    "            \"o_w_bhl_voltage\": 0.0,\n",
    "            \"i_w_bhr_weg\": -5000.0,\n",
    "            \"o_w_bhr_power\": 0.0,\n",
    "            \"o_w_bhr_voltage\": 0.0,\n",
    "            \"i_w_bru_weg\": -50.0,\n",
    "            \"o_w_bru_power\": 200.0,\n",
    "            \"o_w_bru_voltage\": 20.0,\n",
    "            \"i_w_hr_weg\": 0.0,\n",
    "            \"o_w_hr_power\": 9000.0,\n",
    "            \"o_w_hr_voltage\": 50.0,\n",
    "            \"i_w_hl_weg\": 0.0,\n",
    "            \"o_w_hl_power\": None,\n",
    "            \"o_w_hl_voltage\": 24.0,\n",
    "            \"labels\": 1.0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    examples_cleaned = [\n",
    "        {\n",
    "            \"i_w_blo_weg\": -107.0,\n",
    "            \"o_w_blo_power\": 0.0,\n",
    "            \"o_w_blo_voltage\": 0.0,\n",
    "            \"i_w_bhl_weg\": 0.0,\n",
    "            \"o_w_bhl_power\": 0.0,\n",
    "            \"o_w_bhl_voltage\": 0.0,\n",
    "            \"i_w_bhr_weg\": -1268.0,\n",
    "            \"o_w_bhr_power\": 0.0,\n",
    "            \"o_w_bhr_voltage\": 0.0,\n",
    "            \"i_w_bru_weg\": -26.0,\n",
    "            \"o_w_bru_power\": 100.0,\n",
    "            \"o_w_bru_voltage\": 20.0,\n",
    "            \"i_w_hr_weg\": 0.0,\n",
    "            \"o_w_hr_power\": 7168.0,\n",
    "            \"o_w_hr_voltage\": 26.0,\n",
    "            \"i_w_hl_weg\": 0.0,\n",
    "            \"o_w_hl_power\": 7720.0,\n",
    "            \"o_w_hl_voltage\": 24.0,\n",
    "            \"labels\": 1.0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 간단한 Few-shot 프롬프트 생성\n",
    "    example_prompts = f\"Example:\\nRow: {examples[0]}\\nCleaned Row: {examples_cleaned[0]}\\n\"\n",
    "\n",
    "    cleaned_rows = []\n",
    "    prompt = (\n",
    "        f\"Clean the following rows based on the provided example:\\n\"\n",
    "        f\"{example_prompts}\\n\"\n",
    "        f\"Rows: {rows}\\n\"\n",
    "        f\"Provide cleaned rows as a valid JSON array. \"\n",
    "        f\"Cleaned rows: \"\n",
    "    )\n",
    "\n",
    "    # 입력 토큰화\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "\n",
    "    # 모델 출력 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            do_sample=True,\n",
    "            max_new_tokens=1024,  # 새로 생성되는 토큰 수 제한\n",
    "            top_p=0.95       # 상위 확률 토큰만 선택\n",
    "        )\n",
    "    # print(f\"Input token length: {inputs.input_ids.shape[1]}\")\n",
    "    # 출력 디코딩\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # print(f\"Response from LLM: {response}\")  # 디버깅용\n",
    "\n",
    "        # Cleaned rows 부분 추출\n",
    "    try:\n",
    "        # \"Cleaned rows:\" 이후 내용 추출\n",
    "        cleaned_rows_part = response.split(\"JSON array. Cleaned rows:\")[1].strip()\n",
    "\n",
    "        # JSON 배열 형태로 가공\n",
    "        cleaned_rows_str = cleaned_rows_part.replace(\"'\", '\"')  # 단일 따옴표를 이중 따옴표로 변환\n",
    "        cleaned_rows_str = f\"[{cleaned_rows_str}]\"  # JSON 배열로 감싸기\n",
    "\n",
    "        # JSON 파싱\n",
    "        cleaned_rows = json.loads(cleaned_rows_str)\n",
    "        print(\"Parsed JSON:\")\n",
    "        print(cleaned_rows)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "    return cleaned_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4964879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 행 선택 (실험용)\n",
    "single_row_to_clean = [data.iloc[1].to_dict()]  # 단일 행을 리스트로 감쌈\n",
    "\n",
    "# 클리닝 실행\n",
    "cleaned_rows = clean_data_with_llm_in_batches(single_row_to_clean)\n",
    "    \n",
    "\n",
    "# 결과 출력\n",
    "# print(\"\\nOriginal Row:\")\n",
    "# print(single_row_to_clean)\n",
    "print(\"\\nCleaned Row:\")\n",
    "print(cleaned_rows)  # LLM 함수의 반환값이 리스트이므로 첫 번째 요소를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48530d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f4783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
